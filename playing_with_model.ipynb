{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torchvision.transforms as T\n",
    "from presnet import PResNet\n",
    "from hybrid_encoder import HybridEncoder\n",
    "from rtdetrv2_decoder import RTDETRTransformerv2\n",
    "from rtdetr_postprocessor import RTDETRPostProcessor\n",
    "from matcher import HungarianMatcher\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup Feature Extractor\n",
    "presnet = PResNet(depth= 34,\n",
    "                  variant = 'd',\n",
    "                  freeze_at = -1,\n",
    "                  return_idx = [1, 2, 3],\n",
    "                  num_stages = 4,\n",
    "                  freeze_norm = False,\n",
    "                  pretrained = True )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = HybridEncoder(  in_channels = [128, 256, 512],\n",
    "                          feat_strides = [8, 16, 32],\n",
    "                          # intra\n",
    "                          hidden_dim = 256,\n",
    "                          use_encoder_idx = [2],\n",
    "                          num_encoder_layers = 1,\n",
    "                          nhead = 8,\n",
    "                          dim_feedforward = 1024,\n",
    "                          dropout = 0.,\n",
    "                          enc_act = 'gelu' ,\n",
    "                          # cross\n",
    "                          expansion = 0.5,\n",
    "                          depth_mult = 1,\n",
    "                          act = 'silu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder = RTDETRTransformerv2(feat_channels = [256, 256, 256],\n",
    "                              feat_strides = [8, 16, 32],\n",
    "                              hidden_dim = 256,\n",
    "                              num_levels = 3,\n",
    "                              num_layers = 4,\n",
    "                              num_queries = 300,\n",
    "                              num_denoising = 100,\n",
    "                              label_noise_ratio = 0.5,\n",
    "                              box_noise_scale = 1.0, # 1.0 0.4\n",
    "                              eval_idx = 2,\n",
    "                              # NEW\n",
    "                              num_points = [4, 4, 4], # [3,3,3] [2,2,2]\n",
    "                              cross_attn_method = 'default', # default, discrete\n",
    "                              query_select_method = 'agnostic' # default, agnostic \n",
    "                              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "postprocessor = RTDETRPostProcessor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, ) -> None:\n",
    "        super().__init__()\n",
    "        self.backbone = presnet\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        \n",
    "    def forward(self, images, targets = None):\n",
    "        features = self.backbone(images)\n",
    "        features = self.encoder(features)\n",
    "        out = self.decoder(features, targets)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detr = Model()\n",
    "\n",
    "checkpoint = torch.load('detr_checkpoint_desk.pth', map_location='cpu') \n",
    "\n",
    "state = checkpoint['model_state_dict']\n",
    "\n",
    "# NOTE load train mode state -> convert to deploy mode\n",
    "detr.load_state_dict(state)\n",
    "\n",
    "# Model Ready for evaluation\n",
    "detr.eval()\n",
    "detr.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the dataset\n",
    "from dataset import PersonDataset\n",
    "from torch.utils.data import random_split, DataLoader\n",
    "\n",
    "root_dir = '/media/enrique/Extreme SSD/person'\n",
    "sequence_list = [f'person-{i}' for i in range(1, 21)]\n",
    "sequence_list = [\"person-9\"]\n",
    "dataset = PersonDataset(root_dir=root_dir, sequence_list=sequence_list, img_transform_size=(640, 640), template_transform_size=(256, 256), max_num_templates=10, max_detections = 300)\n",
    "\n",
    "# Define the lengths for training and validation sets\n",
    "train_size = int(0.8 * len(dataset))  # 80% for training\n",
    "val_size = len(dataset) - train_size  # The rest for validation\n",
    "\n",
    "# Split the dataset\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "batch_size = 1\n",
    "# Optionally, create DataLoader objects for the training and validation sets\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a single batch from the DataLoader\n",
    "data_iter = iter(train_loader)\n",
    "data = next(data_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = data[\"img\"].cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    output = detr(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_target_sizes = torch.Tensor([640, 640]).cuda()\n",
    "procesed_output = postprocessor(output, orig_target_sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "procesed_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
